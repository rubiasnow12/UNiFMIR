import torch
import argparse
import sys
import os

# 1. å¯¼å…¥æˆ‘ä»¬ä¿®æ”¹åçš„æ¨¡å‹
print("æ­£åœ¨å¯¼å…¥æ¨¡å‹...")
try:
    from model.dinoir_v3 import dinov3  # å¯¼å…¥ dinov3 ç±»ï¼ˆç”¨äº SR ä»»åŠ¡ï¼‰
    from model.dinoir_v3 import DinoUniModel  # å¯¼å…¥é€šç”¨æ¨¡å‹ç±» V1
    from model.dinoir_v3 import DinoUniModelV2  # å¯¼å…¥é€šç”¨æ¨¡å‹ç±» V2 (Task Embedding + FiLM)
    print("...å¯¼å…¥æˆåŠŸï¼")
except Exception as e:
    print(f"å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

# 2. å®šä¹‰ DINOv3 ViT-S æƒé‡æ–‡ä»¶çš„è·¯å¾„
dino_checkpoint_path = 'dinov3_vits16_pretrain_lvd1689m-08c60483.pth' 

# ========== é€‰æ‹©è¦åˆ›å»ºçš„æ¨¡å‹ç±»å‹ ==========
# 'sr'     â†’ dinov3ï¼ˆSR å•ä»»åŠ¡ï¼‰
# 'v1'     â†’ DinoUniModelï¼ˆå¤šå¤´ä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡ç‹¬ç«‹ conv_firstï¼‰
# 'v2'     â†’ DinoUniModelV2ï¼ˆTask Embedding + FiLM è°ƒåˆ¶ + ç»Ÿä¸€è¾“å…¥å±‚ï¼‰
MODEL_TYPE = 'v2'  # â† æ”¹è¿™é‡Œé€‰æ‹©æ¨¡å‹ç‰ˆæœ¬

# æ ¹æ®æ¨¡å‹ç±»å‹è®¾ç½®è¾“å‡ºæ–‡ä»¶å
output_checkpoint_map = {
    'sr': 'dinoir_v3_vits_sr_preload.pth',
    'v1': 'dinoir_v3_vits_unipreload.pth',
    'v2': 'dinoir_v3_vits_v2preload.pth',
}
output_checkpoint_path = output_checkpoint_map[MODEL_TYPE]


# æ„é€ æ¨¡æ‹Ÿå‚æ•°
mock_args = argparse.Namespace()
mock_args.n_resblocks = 8
mock_args.n_feats = 32
mock_args.scale = [1]
mock_args.inch = 1
mock_args.n_colors = 1
mock_args.rgb_range = 1
mock_args.res_scale = 1.0
mock_args.dilation = False

if MODEL_TYPE == 'v2':
    print("æ­£åœ¨å®ä¾‹åŒ– DinoUniModelV2 (Task Embedding + FiLM) æ¨¡å‹...")
    model = DinoUniModelV2(
        args=mock_args,
        embed_dim=384,
        dino_depth=12,
        dino_num_heads=6,
        task_embed_dim=64,
    )
elif MODEL_TYPE == 'v1':
    print("æ­£åœ¨å®ä¾‹åŒ– DinoUniModel V1 (ViT-S) æ¨¡å‹...")
    model = DinoUniModel(
        args=mock_args,
        embed_dim=384,
        dino_depth=12,
        dino_num_heads=6,
    )
else:
    print("æ­£åœ¨å®ä¾‹åŒ– dinov3 (ViT-S) SR ä¸“ç”¨æ¨¡å‹...")
    model = dinov3(
        in_chans=1,
        out_chans=1,
        embed_dim=384,
        dino_depth=12,
        dino_num_heads=6,
        upscale=2,
        use_lora=False,
    )

model_state_dict = model.state_dict()
print("...æ¨¡å‹å®ä¾‹åŒ–æˆåŠŸã€‚")
print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

# 5. åŠ è½½ DINOv3 é¢„è®­ç»ƒæƒé‡
print(f"æ­£åœ¨åŠ è½½ DINOv3 é¢„è®­ç»ƒæƒé‡ä» '{dino_checkpoint_path}'...")
dino_weights = torch.load(dino_checkpoint_path, map_location='cpu')
print("...DINOv3 æƒé‡åŠ è½½æˆåŠŸã€‚")
print(f"DINOv3 æƒé‡åŒ…å« {len(dino_weights)} ä¸ªé”®ã€‚")

# 6. æ ¸å¿ƒæ­¥éª¤ï¼šéƒ¨åˆ†åŠ è½½ (Partial Load)
#    åŠ è½½ DINOv3 çš„ blocks å’Œ norm å±‚åˆ°æˆ‘ä»¬çš„æ¨¡å‹
print("å¼€å§‹åŒ¹é…æƒé‡é”® (key)...")
new_state_dict = {}
loaded_keys = 0
skipped_keys = []

for dino_key, dino_value in dino_weights.items():
    # æˆ‘ä»¬å…³å¿ƒ 'blocks' (Transformer ä¸»å¹²) å’Œ 'norm' (æœ€ç»ˆå½’ä¸€åŒ–å±‚)
    if dino_key.startswith('blocks.') or dino_key.startswith('norm.'):
        # æ£€æŸ¥è¿™ä¸ªé”®æ˜¯å¦å­˜åœ¨äºæˆ‘ä»¬çš„æ¨¡å‹ä¸­
        if dino_key in model_state_dict:
            # æ£€æŸ¥å½¢çŠ¶æ˜¯å¦åŒ¹é…
            if model_state_dict[dino_key].shape == dino_value.shape:
                new_state_dict[dino_key] = dino_value
                loaded_keys += 1
            else:
                skipped_keys.append(f"{dino_key} (å½¢çŠ¶ä¸åŒ¹é…: {dino_value.shape} vs {model_state_dict[dino_key].shape})")
        else:
            skipped_keys.append(f"{dino_key} (æ¨¡å‹ä¸­ä¸å­˜åœ¨)")

print(f"...åŒ¹é…å®Œæˆã€‚")
print(f"  âœ… æˆåŠŸåŒ¹é…å¹¶å‡†å¤‡åŠ è½½ {loaded_keys} ä¸ªé”® (æ¥è‡ª 'blocks' å’Œ 'norm')ã€‚")
print(f"  â­ï¸  è·³è¿‡äº† {len(skipped_keys)} ä¸ªä¸ç›¸å…³/ä¸åŒ¹é…çš„é”®ã€‚")
if skipped_keys and len(skipped_keys) <= 10:
    print("  è·³è¿‡çš„é”®:")
    for k in skipped_keys:
        print(f"    - {k}")

# 7. åŠ è½½è¿‡æ»¤åçš„æƒé‡åˆ°æˆ‘ä»¬çš„æ¨¡å‹ä¸­
#    strict=False æ„å‘³ç€å®ƒä¼šå¿½ç•¥æ‰€æœ‰ "Missing key(s)" 
#    (ä¾‹å¦‚ patch_embed, upsample, conv_last ç­‰ï¼Œè¿™æ˜¯æˆ‘ä»¬æœŸæœ›çš„)
print("æ­£åœ¨å°† DINOv3 backbone æƒé‡åŠ è½½åˆ°æ–°æ¨¡å‹ä¸­...")
model.load_state_dict(new_state_dict, strict=False)
print("...éƒ¨åˆ†åŠ è½½æˆåŠŸï¼")

# 8. ä¿å­˜æ–°çš„æ··åˆæƒé‡æ–‡ä»¶
print(f"æ­£åœ¨å°†éƒ¨åˆ†åŠ è½½çš„æ¨¡å‹ä¿å­˜åˆ° '{output_checkpoint_path}'...")
torch.save(model.state_dict(), output_checkpoint_path)

print("\n" + "="*60)
print("âœ… å…¨éƒ¨å®Œæˆ!")
print("="*60)
print(f"\nğŸ“ ç”Ÿæˆçš„æƒé‡æ–‡ä»¶: '{output_checkpoint_path}'")
print(f"\nğŸ“ æ¨¡å‹ç±»å‹: {MODEL_TYPE}")
if MODEL_TYPE == 'v2':
    print("\nğŸ“ V2 å¤šä»»åŠ¡è®­ç»ƒæµç¨‹ (Task Embedding + FiLM):")
    print("   1. åœ¨ mainUi_pretrain.py ä¸­è®¾ç½®:")
    print("      - USE_V2 = True")
    print("      - freeze_depth = 0  (å†»ç»“å‰0å±‚)")
    print(f"      - preloaded_path = './{output_checkpoint_path}'")
    print("   2. è¿è¡Œ python mainUi_pretrain.py")
    print("   3. ç³»ç»Ÿä¼šè‡ªåŠ¨: åŠ è½½æƒé‡ â†’ FiLM è°ƒåˆ¶å¤šä»»åŠ¡è®­ç»ƒ")
else:
    print("\nğŸ“ V1/SR è®­ç»ƒæµç¨‹:")
    print(f"      - preloaded_path = './{output_checkpoint_path}'")
    print("   è¿è¡Œ python mainUi_pretrain.py æˆ– python mainSR_dino.py")