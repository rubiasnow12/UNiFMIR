"""
DINOv3-based Denoising å¾®è°ƒè„šæœ¬

ç”¨äºè®­ç»ƒåŸºäº DINOv3 backbone çš„ 3D å»å™ªæ¨¡å‹ã€‚
æ”¯æŒ Planaria å’Œ Tribolium æ•°æ®é›†ã€‚
"""
import torch
torch.backends.cudnn.enabled = False
import utility
import loss
import argparse
from div2k import Flourescenedenoise
from trainer import Trainer
from torch.utils.data import dataloader
import model
import os
import wandb


def options():
    parser = argparse.ArgumentParser(description='DINOv3 Denoising')
    parser.add_argument('--model', default=modelname, help='model name')
    parser.add_argument('--test_only', action='store_true', default=test_only,
                        help='set this option to test the model')
    
    scale = 1  # Denoise ä»»åŠ¡ scale=1
    parser.add_argument('--modelpath', type=str, default=modelpath, help='é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„')
    parser.add_argument('--resume', type=int, default=resume, help='-2:best;-1:latest.ptb; 0:pretrain; >0: resume')
    parser.add_argument('--save', type=str, default=savepath, help='ä¿å­˜è·¯å¾„')
    parser.add_argument('--pre_train', type=str, default=modelpath)
    parser.add_argument('--prune', action='store_true', help='prune layers')

    # Data specifications
    parser.add_argument('--data_test', type=str, default=testset, help='demo image directory')
    parser.add_argument('--epochs', type=int, default=epoch, help='number of epochs to train')
    parser.add_argument('--rgb_range', type=int, default=1, help='maximum value of RGBn_colors')
    parser.add_argument('--n_colors', type=int, default=1, help='')
    parser.add_argument('--inputchannel', type=int, default=inputchannel, help='è¾“å…¥é€šé“æ•°')
    parser.add_argument('--datamin', type=int, default=0)
    parser.add_argument('--datamax', type=int, default=100)
    parser.add_argument('--condition', type=int, default=condition)

    parser.add_argument('--batch_size', type=int, default=batchsize, help='input batch size for training')
    parser.add_argument('--patch_size', type=int, default=patch_size, help='input batch size for training')
    parser.add_argument('--cpu', action='store_true', default=False, help='')
    parser.add_argument('--print_every', type=int, default=400)
    parser.add_argument('--test_every', type=int, default=30000)
    
    parser.add_argument('--n_GPUs', type=int, default=1, help='number of GPUs')
    
    parser.add_argument('--chop', action='store_true', default=True, help='enable memory-efficient forward')
    parser.add_argument('--load', type=str, default='', help='file name to load')
    parser.add_argument('--debug', action='store_true', help='Enables debug mode')
    parser.add_argument('--scale', type=str, default='%d' % scale, help='super resolution scale')
    parser.add_argument('--chunk_size', type=int, default=144, help='attention bucket size')
    parser.add_argument('--n_hashes', type=int, default=4, help='number of hash rounds')
    
    # Model specifications
    parser.add_argument('--extend', type=str, default='.', help='pre-trained model directory')
    parser.add_argument('--shift_mean', default=True, help='subtract pixel mean from the input')
    parser.add_argument('--precision', type=str, default='single', choices=('single', 'half'), 
                        help='FP precision for test (single | half)')

    parser.add_argument('--seed', type=int, default=1, help='random seed')
    parser.add_argument('--local_rank', type=int, default=0)
    
    # å†»ç»“ backbone é€‰é¡¹
    # ========== å…³é”®ä¿®æ”¹ 3: é»˜è®¤å¼€å¯éƒ¨åˆ†å†»ç»“ ==========
    parser.add_argument('--freeze_backbone', action='store_true', default=True,
                        help='Freeze the DINOv3 backbone (blocks) and only train the head/tail.')

    # Hardware specifications
    parser.add_argument('--n_threads', type=int, default=0, help='number of threads for data loading')
    # Training specifications
    parser.add_argument('--reset', action='store_true', help='reset the training')
    parser.add_argument('--split_batch', type=int, default=1, help='split the batch into smaller chunks')
    parser.add_argument('--self_ensemble', action='store_true', help='use self-ensemble method for test')
    
    # Optimization specifications
    parser.add_argument('--lr', type=float, default=lr, help='learning rate')
    parser.add_argument('--decay', type=str, default='cosine', help='learning rate decay type')
    parser.add_argument('--gamma', type=float, default=0.5, help='learning rate decay factor for step decay')
    parser.add_argument('--optimizer', default='ADAM', choices=('SGD', 'ADAM', 'RMSprop'),
                        help='optimizer to use (SGD | ADAM | RMSprop)')
    parser.add_argument('--momentum', type=float, default=0.9, help='SGD momentum')
    parser.add_argument('--betas', type=tuple, default=(0.9, 0.999), help='ADAM beta')
    parser.add_argument('--epsilon', type=float, default=1e-8, help='ADAM epsilon for numerical stability')
    parser.add_argument('--weight_decay', type=float, default=0, help='weight decay')
    # ========== å…³é”®ä¿®æ”¹ 2: å¼€å¯æ¢¯åº¦è£å‰ª ==========
    parser.add_argument('--gclip', type=float, default=1.0, help='gradient clipping threshold (0 = no clipping)')
    
    # Loss specifications
    # ========== å…³é”®ä¿®æ”¹ 5: ä½¿ç”¨æ··åˆæŸå¤±å‡½æ•° ==========
    # L1 + SSIM ç»„åˆå¯ä»¥æä¾›æ›´ç¨³å®šçš„è®­ç»ƒ
    parser.add_argument('--loss', type=str, default='1*L1+0.1*SSIM', help='loss function configuration')
    parser.add_argument('--skip_threshold', type=float, default='1e8', help='skipping batch that has large error')
    
    # Log specifications
    parser.add_argument('--save_models', action='store_true', default=True, help='save all intermediate models')
    parser.add_argument('--save_results', action='store_true', default=True, help='save output results')
    parser.add_argument('--patience', type=int, default=5000, help='Early stopping patience')
    
    parser.add_argument('--wandb_id', type=str, default=None, help='wandb run id to resume')
    
    args = parser.parse_args()
    
    args.scale = list(map(lambda x: int(x), args.scale.split('+')))
    
    for arg in vars(args):
        if vars(args)[arg] == 'True':
            vars(args)[arg] = True
        elif vars(args)[arg] == 'False':
            vars(args)[arg] = False
    
    return args


def main():
    _model = model.Model(args, checkpoint)

    if args.prune:
        prune_layers = 1
        print(f"Pruning {prune_layers} layers...")
        # æ³¨æ„ï¼šDINOv3 ä½¿ç”¨ 'blocks' è€Œä¸æ˜¯ 'layers'
        if hasattr(_model.model, 'blocks'):
            del _model.model.blocks[prune_layers]
        elif hasattr(_model.model, 'layers'):
            del _model.model.layers[prune_layers]

    if not args.test_only:
        loader_train = dataloader.DataLoader(
            Flourescenedenoise(args, istrain=True),
            batch_size=args.batch_size,
            shuffle=True,
            pin_memory=not args.cpu,
            num_workers=4,
        )
    else:
        loader_train = None
    
    loader_test = [dataloader.DataLoader(
        Flourescenedenoise(args, istrain=False, c=condition),
        batch_size=1,
        shuffle=False,
        pin_memory=not args.cpu,
        num_workers=args.n_threads,
    )]
    
    _loss = loss.Loss(args, checkpoint) if not args.test_only else None
    t = Trainer(args, loader_train, loader_test, args.data_test, _model, _loss, checkpoint)
    
    if test_only:
        t.test3DdenoiseInchannel5(condition=condition)
    else:
        while t.terminate():
            t.train()
    
    if hasattr(t, 'done'):
        t.done()
    checkpoint.done()

    
if __name__ == '__main__':
    test_only = False
    normrange = 'Norm_0-100'
    
    # é€‰æ‹©æ•°æ®é›†: 'Denoising_Planaria' æˆ– 'Denoising_Tribolium'
    testsetlst = ['Denoising_Planaria']  # ['Denoising_Tribolium']
    
    # æ ¹æ®æ•°æ®é›†è°ƒæ•´å‚æ•°
    if testsetlst[0] == 'Denoising_Planaria':
        modelname = 'DINOIRv3'  # æ”¹ä¸º DINOv3
        inputchannel = 1  # Planaria æ˜¯å•é€šé“è¾“å…¥
        resume = 0  # ä»é¢„è®­ç»ƒå¼€å§‹
    else:
        modelname = 'DINOIRv3mto1'  # Tribolium å¤šé€šé“è¾“å…¥
        inputchannel = 5
        resume = 0

    # è®­ç»ƒè¶…å‚æ•°
    batchsize = 8  # Denoise ä»»åŠ¡é€šå¸¸ batch è¾ƒå°
    patch_size = 64
    epoch = 500
    # ========== å…³é”®ä¿®æ”¹ 1: é™ä½å­¦ä¹ ç‡ ==========
    # DINOv3 é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒå»ºè®®ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡
    lr = 2e-5  # åŸæ¥ 1e-4 å¤ªå¤§ï¼Œå¯¼è‡´éœ‡è¡
    datamin, datamax = 0, 100
    
    # é¢„è®­ç»ƒæƒé‡è·¯å¾„
    initial_weights_path = './dinoir_v3_vitb_unipreload.pth'
    
    for condition in range(1, 4):  # éå†ä¸åŒçš„ condition
        for testset in testsetlst:
            savepath = '%s%s/' % (modelname, testset)
            modelpath = initial_weights_path
            
            args = options()
            
            # ========== å…³é”®ä¿®æ”¹ 4: æ­£ç¡®è®¾ç½®é€šé“æ•° ==========
            # æ•°æ®æœ¬èº«æ˜¯å•é€šé“ï¼Œä½†æ¨¡å‹éœ€è¦ä¸‰é€šé“è¾“å…¥ï¼ˆé¢„è®­ç»ƒè¦æ±‚ï¼‰
            # args.inputchannel ç”¨äºæ•°æ®é›†åŠ è½½ï¼Œåº”ä¸å®é™…æ•°æ®åŒ¹é…
            # æ¨¡å‹ä¼šåœ¨ forward ä¸­è‡ªåŠ¨å¤åˆ¶å•é€šé“åˆ°ä¸‰é€šé“
            if testsetlst[0] == 'Denoising_Planaria':
                args.inputchannel = 1  # Planaria æ•°æ®æ˜¯å•é€šé“
            else:
                args.inputchannel = 5  # Tribolium æ˜¯å¤šé€šé“
            
            # æ¨¡å‹å†…éƒ¨é€šé“è®¾ç½®ï¼ˆæ¨¡å‹ä¼šè‡ªåŠ¨å¤„ç† 1->3 çš„è½¬æ¢ï¼‰
            args.inch = 3
            args.n_colors = 3
            
            # è¦†ç›–å‚æ•°
            args.modelpath = modelpath
            args.resume = resume
            args.test_only = test_only
            args.epochs = epoch
            args.lr = lr
            args.batch_size = batchsize
            args.patch_size = patch_size
            args.save = savepath
            args.condition = condition
            
            print(f"\n{'='*60}")
            print(f"ğŸš€ å¼€å§‹è®­ç»ƒ: {testset}, Condition={condition}")
            print(f"   æ¨¡å‹: {modelname}")
            print(f"   ä¿å­˜è·¯å¾„: {savepath}")
            print(f"{'='*60}\n")
            
            torch.manual_seed(args.seed)
            checkpoint = utility.checkpoint(args)
            main()
