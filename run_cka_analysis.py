"""
CKA ç‰¹å¾ç›¸ä¼¼æ€§åˆ†æè„šæœ¬ã€‚

ç”¨æ³•ï¼š
    python run_cka_analysis.py --model_path ./experiment/Uni-DINOv3-pretrain-lora/model/model_best.pt \\
                               --model_version v2

åŠŸèƒ½ï¼š
    1. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    2. åˆ†åˆ«ç”¨ SR å’Œ Denoise æ•°æ®è®¡ç®—æ¯ä¸€å±‚ Transformer Block çš„ç‰¹å¾
    3. è®¡ç®—è·¨ä»»åŠ¡ CKA ç›¸ä¼¼åº¦çŸ©é˜µ
    4. ç»˜åˆ¶çƒ­åŠ›å›¾

é¢„æœŸç»“æœï¼š
    - æµ…å±‚ (Layer 1-4)ï¼šé«˜ CKA â†’ å…±äº«çº¹ç†/è¾¹ç¼˜ç‰¹å¾ï¼ˆæ‰“ç ´äº†ä¿¡æ¯å­¤å²›ï¼‰
    - æ·±å±‚ (Layer 9-12)ï¼šä½ CKA â†’ Prompt å¼•å¯¼äº†ä»»åŠ¡ç‰¹å¼‚æ€§åˆ†åŒ–
"""

import torch
import argparse
import os
import sys
import numpy as np
from torch.utils.data import DataLoader

# é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from model.dinoir_v3 import DinoUniModel, DinoUniModelV2
from mydata import SR, Flourescenedenoise
from analysis import CKAAnalyzer
import model


def parse_args():
    parser = argparse.ArgumentParser(description='CKA Feature Similarity Analysis')
    parser.add_argument('--model_path', type=str, default='./experiment/Uni-DINOv3-pretrain-lora/model/',
                        help='è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„')
    parser.add_argument('--model_version', type=str, default='v2', choices=['v1', 'v2'],
                        help='æ¨¡å‹ç‰ˆæœ¬: v1=DinoUniModel, v2=DinoUniModelV2')
    parser.add_argument('--resume', type=int, default=-2, help='-2=best, -1=latest, >0=specific epoch')
    parser.add_argument('--num_samples', type=int, default=100,
                        help='CKA åˆ†æä½¿ç”¨çš„æ ·æœ¬æ•°ï¼ˆè¶Šå¤šè¶Šå‡†ï¼Œä½†è¶Šæ…¢ï¼‰')
    parser.add_argument('--sr_dataset', type=str, default='F-actin',
                        help='SR æ•°æ®é›†åç§°')
    parser.add_argument('--dn_dataset', type=str, default='Denoising_Planaria',
                        help='Denoise æ•°æ®é›†åç§°')
    parser.add_argument('--output_dir', type=str, default='./experiment/cka_analysis',
                        help='è¾“å‡ºç›®å½•')
    parser.add_argument('--patch_size', type=int, default=64)

    # --- Baseline å¯¹æ¯” ---
    parser.add_argument('--baseline_path', type=str, default='',
                        help='Baseline æ¨¡å‹è·¯å¾„ï¼ˆç”¨äºå¯¹æ¯”å›¾ï¼‰')

    return parser.parse_args()


def build_model(version, device):
    """æ„å»ºæ¨¡å‹å®ä¾‹"""
    mock_args = argparse.Namespace()
    mock_args.n_resblocks = 8
    mock_args.n_feats = 32
    mock_args.scale = [1]
    mock_args.inch = 1
    mock_args.n_colors = 1
    mock_args.rgb_range = 1
    mock_args.res_scale = 1.0
    mock_args.dilation = False
    mock_args.chop = True
    mock_args.self_ensemble = False
    mock_args.precision = 'single'
    mock_args.n_GPUs = 1
    mock_args.save_models = False
    mock_args.save = 'cka_analysis'
    mock_args.model = 'Uni-DINOv3'
    mock_args.cpu = not torch.cuda.is_available()
    mock_args.test_only = True
    mock_args.load = ''
    mock_args.resume = 0
    mock_args.pre_train = '.'
    mock_args.template = '.'

    if version == 'v2':
        unimodel = DinoUniModelV2(
            mock_args, embed_dim=384, dino_depth=12, dino_num_heads=6,
            task_embed_dim=64
        )
    else:
        unimodel = DinoUniModel(
            mock_args, embed_dim=384, dino_depth=12, dino_num_heads=6
        )

    return unimodel.to(device), mock_args


def load_model_weights(unimodel, model_path, resume=-2):
    """åŠ è½½æ¨¡å‹æƒé‡"""
    if os.path.isdir(model_path):
        if resume == -2:
            # åŠ è½½ best
            ckpt_path = os.path.join(model_path, 'model_best.pt')
            if not os.path.exists(ckpt_path):
                ckpt_path = os.path.join(model_path, 'model_latest.pt')
        elif resume == -1:
            ckpt_path = os.path.join(model_path, 'model_latest.pt')
        else:
            ckpt_path = os.path.join(model_path, f'model_{resume}.pt')
    else:
        ckpt_path = model_path

    if os.path.exists(ckpt_path):
        print(f"Loading model weights from {ckpt_path}")
        state_dict = torch.load(ckpt_path, map_location='cpu')
        # å¤„ç†å¯èƒ½çš„ model.model. å‰ç¼€
        new_state_dict = {}
        for k, v in state_dict.items():
            new_key = k.replace('model.model.', '').replace('model.', '')
            new_state_dict[new_key] = v

        model_state = unimodel.state_dict()
        filtered = {k: v for k, v in new_state_dict.items()
                    if k in model_state and v.shape == model_state[k].shape}
        unimodel.load_state_dict(filtered, strict=False)
        print(f"Loaded {len(filtered)}/{len(new_state_dict)} keys")
    else:
        print(f"Warning: {ckpt_path} not found!")

    return unimodel


def get_data_loaders(sr_dataset, dn_dataset, patch_size):
    """å‡†å¤‡ SR å’Œ Denoise æ•°æ®é›†çš„ DataLoader"""
    srdatapath = './CSB/DataSet/BioSR_WF_to_SIM/DL-SR-main/dataset/'
    denoisedatapath = './CSB/DataSet/'

    sr_loader = DataLoader(
        SR(scale=2, name=sr_dataset, train=False, test_only=True,
           rootdatapath=srdatapath, patch_size=patch_size, length=20),
        batch_size=1, shuffle=False, num_workers=0
    )

    dn_loader = DataLoader(
        Flourescenedenoise(name=dn_dataset, istrain=False, c=1,
                           rootdatapath=denoisedatapath, test_only=True,
                           patch_size=patch_size, length=2000),
        batch_size=1, shuffle=False, num_workers=0
    )

    return sr_loader, dn_loader


class ModelWrapper:
    """ç®€å•åŒ…è£…å™¨ï¼Œè®© CKAAnalyzer å¯ä»¥ç»Ÿä¸€è°ƒç”¨"""
    def __init__(self, unimodel, device):
        self.model = unimodel
        self.device = device
        self.training = unimodel.training

    def eval(self):
        self.model.eval()
        self.training = False

    def train(self):
        self.model.train()
        self.training = True

    def __call__(self, x, tsk):
        return self.model(x, tsk)


def main():
    args = parse_args()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Device: {device}")

    os.makedirs(args.output_dir, exist_ok=True)
    cka_analyzer = CKAAnalyzer(save_dir=args.output_dir)

    # ======== æ„å»ºå¹¶åŠ è½½ Ours æ¨¡å‹ ========
    print("\n" + "="*60)
    print(f"åŠ è½½ Ours æ¨¡å‹ ({args.model_version})...")
    print("="*60)
    unimodel, mock_args = build_model(args.model_version, device)
    unimodel = load_model_weights(unimodel, args.model_path, args.resume)
    unimodel.eval()
    wrapper = ModelWrapper(unimodel, device)

    # ======== å‡†å¤‡æ•°æ® ========
    print("\nåŠ è½½æ•°æ®é›†...")
    sr_loader, dn_loader = get_data_loaders(args.sr_dataset, args.dn_dataset, args.patch_size)
    print(f"  SR ({args.sr_dataset}): {len(sr_loader)} batches")
    print(f"  Denoise ({args.dn_dataset}): {len(dn_loader)} batches")

    # ======== æå–ç‰¹å¾ ========
    print("\n" + "="*60)
    print("æå– SR ä»»åŠ¡ç‰¹å¾...")
    print("="*60)
    features_sr = cka_analyzer.extract_layer_features(
        wrapper, sr_loader, task_id=1,
        num_samples=args.num_samples, device=device
    )
    print(f"  æå–äº† {len(features_sr)} å±‚çš„ç‰¹å¾")
    for k, v in features_sr.items():
        print(f"    Block {k}: {v.shape}")

    print("\næå– Denoise ä»»åŠ¡ç‰¹å¾...")
    features_dn = cka_analyzer.extract_layer_features(
        wrapper, dn_loader, task_id=2,
        num_samples=args.num_samples, device=device
    )
    print(f"  æå–äº† {len(features_dn)} å±‚çš„ç‰¹å¾")

    # ======== è®¡ç®— CKA çŸ©é˜µ ========
    print("\n" + "="*60)
    print("è®¡ç®— CKA ç›¸ä¼¼åº¦çŸ©é˜µ...")
    print("="*60)
    cka_matrix = cka_analyzer.compute_cross_task_cka(features_sr, features_dn)
    print(f"  CKA çŸ©é˜µå½¢çŠ¶: {cka_matrix.shape}")

    # æ‰“å°å¯¹è§’çº¿å€¼
    diag = np.diag(cka_matrix)
    print("\n  åŒå±‚è·¨ä»»åŠ¡ CKA (å¯¹è§’çº¿):")
    for i, val in enumerate(diag):
        marker = "ğŸŸ¢" if val > 0.5 else "ğŸŸ¡" if val > 0.3 else "ğŸ”´"
        print(f"    {marker} Block {i:2d}: {val:.4f}")

    print(f"\n  æµ…å±‚å¹³å‡ (0-3): {diag[:4].mean():.4f}")
    print(f"  ä¸­å±‚å¹³å‡ (4-7): {diag[4:8].mean():.4f}")
    print(f"  æ·±å±‚å¹³å‡ (8-11): {diag[8:].mean():.4f}")

    # ======== ä¿å­˜ç»“æœå’Œç»˜å›¾ ========
    cka_analyzer.save_cka_matrix(cka_matrix, 'SR', 'Denoise',
                                 f'cka_ours_{args.model_version}.npz')

    output_path = os.path.join(args.output_dir,
                               f'cka_heatmap_ours_{args.model_version}.png')
    CKAAnalyzer.plot_cka_heatmap(
        cka_matrix, task1_name='SR', task2_name='Denoise',
        output_path=output_path,
        title_suffix=f'(Ours: {args.model_version.upper()} Task-Prompted FiLM)'
    )

    # ======== (å¯é€‰) Baseline å¯¹æ¯” ========
    if args.baseline_path and os.path.exists(args.baseline_path):
        print("\n" + "="*60)
        print("åŠ è½½ Baseline æ¨¡å‹ (v1)...")
        print("="*60)
        baseline_model, _ = build_model('v1', device)
        baseline_model = load_model_weights(baseline_model, args.baseline_path, args.resume)
        baseline_model.eval()
        baseline_wrapper = ModelWrapper(baseline_model, device)

        features_sr_base = cka_analyzer.extract_layer_features(
            baseline_wrapper, sr_loader, task_id=1,
            num_samples=args.num_samples, device=device
        )
        features_dn_base = cka_analyzer.extract_layer_features(
            baseline_wrapper, dn_loader, task_id=2,
            num_samples=args.num_samples, device=device
        )
        cka_baseline = cka_analyzer.compute_cross_task_cka(features_sr_base, features_dn_base)

        comp_path = os.path.join(args.output_dir, 'cka_comparison_baseline_vs_ours.png')
        CKAAnalyzer.plot_comparison(
            cka_baseline, cka_matrix,
            task1_name='SR', task2_name='Denoise',
            output_path=comp_path
        )

    print("\n" + "="*60)
    print("âœ… CKA åˆ†æå®Œæˆ!")
    print("="*60)
    print(f"\nğŸ“ ç»“æœä¿å­˜åœ¨: {args.output_dir}/")
    print("ğŸ“Š å¦‚éœ€ç”Ÿæˆ Baseline å¯¹æ¯”å›¾ï¼Œè¯·æŒ‡å®š --baseline_path å‚æ•°")


if __name__ == '__main__':
    main()
